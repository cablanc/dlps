{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "from utils import compute_confusion_matrix, train, evaluate\n",
    "from networks import RecurrentNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define hyperparameters etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pendulum\n",
    "m = 1.\n",
    "g = 9.81\n",
    "l = 1.\n",
    "dt = 1e-2\n",
    "\n",
    "datadir = '../datasets'\n",
    "sequence_len = 28\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "num_epochs = 1\n",
    "outdim = 10\n",
    "indim = 28\n",
    "hdim = 128\n",
    "print_every = 100\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset has 60000, test dataset has 10000\n"
     ]
    }
   ],
   "source": [
    "# define transform to map data from a PIL.Image data type\n",
    "# to a Tensor which is what pytorch uses\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(0.5, 0.5)])\n",
    "\n",
    "# (down)load training and testing datasets\n",
    "emnist_traindata = torchvision.datasets.EMNIST(datadir, split='mnist', download=True, transform=transform)\n",
    "emnist_testdata = torchvision.datasets.EMNIST(datadir, split='mnist', train=False, download=True, transform=transform)\n",
    "\n",
    "train_num_examples, _, _ = emnist_traindata.data.shape\n",
    "test_num_examples, _, _ = emnist_testdata.data.shape\n",
    "\n",
    "print('Training dataset has {train_num_examples}, test dataset has {test_num_examples}'.format(train_num_examples=train_num_examples, test_num_examples=test_num_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RecurrentNN(indim, hdim, outdim, num_layers, sequence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters in the network is: 87562\n"
     ]
    }
   ],
   "source": [
    "params = rnn.parameters()\n",
    "num_params = np.sum([np.prod(p.shape) for p in params])\n",
    "print('The number of parameters in the network is: {}'.format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fcn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "trainloader = torch.utils.data.DataLoader(emnist_traindata, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "testloader = torch.utils.data.DataLoader(emnist_testdata, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Iteration: 0, Loss: 2.34, Acc: 0.06\n",
      "Epoch: 0, Iteration: 100, Loss: 1.78, Acc: 0.44\n",
      "Epoch: 0, Iteration: 200, Loss: 1.21, Acc: 0.62\n",
      "Epoch: 0, Iteration: 300, Loss: 1.09, Acc: 0.59\n",
      "Epoch: 0, Iteration: 400, Loss: 1.02, Acc: 0.62\n",
      "Epoch: 0, Iteration: 500, Loss: 0.92, Acc: 0.69\n",
      "Epoch: 0, Iteration: 600, Loss: 0.66, Acc: 0.81\n",
      "Epoch: 0, Iteration: 700, Loss: 0.39, Acc: 0.84\n",
      "Epoch: 0, Iteration: 800, Loss: 0.74, Acc: 0.81\n",
      "Epoch: 0, Iteration: 900, Loss: 0.38, Acc: 0.91\n",
      "Epoch: 0, Iteration: 1000, Loss: 0.42, Acc: 0.88\n",
      "Epoch: 0, Iteration: 1100, Loss: 0.58, Acc: 0.88\n",
      "Epoch: 0, Iteration: 1200, Loss: 0.36, Acc: 0.94\n",
      "Epoch: 0, Iteration: 1300, Loss: 1.31, Acc: 0.66\n",
      "Epoch: 0, Iteration: 1400, Loss: 0.40, Acc: 0.88\n",
      "Epoch: 0, Iteration: 1500, Loss: 0.45, Acc: 0.84\n",
      "Epoch: 0, Iteration: 1600, Loss: 0.23, Acc: 0.91\n",
      "Epoch: 0, Iteration: 1700, Loss: 0.58, Acc: 0.81\n"
     ]
    }
   ],
   "source": [
    "# make weights trainable\n",
    "rnn.train()\n",
    "\n",
    "# run training loop\n",
    "training_loss = train(num_epochs, print_every, trainloader, loss_fcn, optimizer, rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training loss\n",
    "plt.plot(training_loss)\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Cross Entropy Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.eval()\n",
    "\n",
    "average_accuracy, average_loss, prediction_label_data = evaluate(testloader, loss_fcn, rnn)\n",
    "    \n",
    "print('Avg Loss: {loss:.2f}, Avg Acc: {acc:.2f}'.format(loss=average_loss, acc=average_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix, mistakes = compute_confusion_matrix(prediction_label_data)\n",
    "# get image with wrong prediction\n",
    "mistake_idx = np.random.randint(len(mistakes))\n",
    "mistake_pred, mistake_label, mistake_data = mistakes[mistake_idx]\n",
    "mistake_img = mistake_data.squeeze().T\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.log(confusion_matrix))\n",
    "plt.title('Log Confusion matrix')\n",
    "plt.xlabel('label')\n",
    "plt.ylabel('prediction')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(mistake_img)\n",
    "plt.title('Label: {label}, Prediction {pred}'.format(label=mistake_label, pred=mistake_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "# https://distill.pub/2016/augmented-rnns/\n",
    "# Theory of gating in recurrent neural networks, Krishnamurthy et al. - https://arxiv.org/abs/2007.14823"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
